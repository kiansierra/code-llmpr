{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python Debugger: Current File",
      "type": "debugpy",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "justMyCode": false,
    },
    {
      "name": "Accelerate: Train SFT",
      "type": "debugpy",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "args": ["src/train_sft.py"],
      "justMyCode": false
    },
    {
      "name": "Rewrite Texts",
      "type": "debugpy",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": [
        "--num_samples", "2000",
        "--seed", "42",
        "--version", "2"
      ]
    },
    {
      "name": "Debug axolotl prompt - sharegpt",
      "type": "debugpy",
      "module": "accelerate.commands.launch",
      "request": "launch",
      "args": [
        "-m",
        "axolotl.cli.train",
        "axolotl/devtools/dev_sharegpt_local.yml",
        // The flags below simplify debugging by overriding the axolotl config
        // with the debugging tips above.  Modify as needed.
        "--dataset_processes=1", // limits data preprocessing to one process
        "--max_steps=1", // limits training to just one step
        "--batch_size=1", // minimizes batch size
        "--micro_batch_size=1", // minimizes batch size
        "--val_set_size=0", // disables validation
        "--sample_packing=False", // disables sample packing which is necessary for small datasets
        "--eval_sample_packing=False", // disables sample packing on eval set
        "--dataset_prepared_path=temp_debug/axolotl_outputs/data", // send data outputs to a temp folder
        "--output_dir=temp_debug/axolotl_outputs/model" // send model outputs to a temp folder
      ],
      "console": "integratedTerminal", // show output in the integrated terminal
      "cwd": "${workspaceFolder}", // set working directory to devtools from the root of the project
      "justMyCode": true, // step through only axolotl code
      "env": { "CUDA_VISIBLE_DEVICES": "0",
        "HF_HOME": "${workspaceFolder}/axolotl/temp_debug/axolotl_outputs/.hf-cache"}, // Since we aren't doing distributed training, we need to limit to one GPU}, // send HF cache to a temp folder
       "preLaunchTask": "cleanup-for-dataprep", // delete temp folders (see below)
    }
  ]
}
